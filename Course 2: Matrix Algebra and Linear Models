##week 2
# Testing Linear model

g = 9.8 ## meters per second
h0 = 56.67
v0 = 0
n = 25
tt = seq(0,3.4,len=n) ##time in secs, t is a base function
y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1)

#equivalent to
X = cbind(1,tt,tt^2)
A = solve(crossprod(X))%*%t(X)

#QUESTION 2.1.1
#Given how we have defined A, which of the following is the LSE of g, the acceleration due to gravity (suggestion: try the code in R)?
-2 * (A %*% y)

#QUESTION 2.1.2
#In the lines of code above, there was a call to a random function rnorm(). This means that each time the lines of code above are repeated, the estimate of g will be different.
#Use the code above in conjunction with the function replicate() to generate 100,000 Monte Carlo simulated datasets. For each dataset compute an estimate of g (remember to multiply by -2)

#What is the standard error of this estimate?
betahat <- replicate(100000, {
  y <- h0 + v0*tt - 0.5*g*tt^2 + rnorm(n,sd=1)  #equivalent to X<-c(1,tt,tt^2)
  betahats <- -2 * (A %*% y)
  return(betahats[3])
})
sd(betahat)

x = father.son$fheight
beta = c(34,0.5)
var(beta[1]+beta[2]*2)
y=h0+v0*tt-0.5*g*tt^2+rnorm(n,sd=1)
var(y)

#QUESTION 2.1.3  
x = father.son$fheight
y = father.son$sheight
n = length(y)
N = 50
set.seed(1)
index = sample(n,N)
sampledat = father.son[index,]
x = sampledat$fheight
y = sampledat$sheight

#Use the function replicate to take 10,000 samples.What is the standard error of the slope estimate? That is, calculate the standard deviation of the estimate from many random samples.
betahat <- replicate(10000,{
index = sample(n,N)
sampledat = father.son[index,]
x = sampledat$fheight
y = sampledat$sheight
return(lm(y~x)$coef[2])
}
)
sd(betahat)

#QUESTION 2.1.4
#We are defining a new concept: covariance. The covariance of two lists of numbers X=X1,...,Xn and Y=Y1,...,Yn is mean( (Y - mean(Y))*(X-mean(X) ) ).
#Which of the following is closest to the covariance between father heights and son heights

cov(father.son$fheight,father.son$sheight)
#equivalent to
mean((father.son$fheight-mean(father.son$fheight))*(father.son$sheight-mean(father.son$sheight)))

#QUESTION 2.2.1  
SE(betahat) = sqrt(var(betahat))
var(betahat) = sigma^2 (X^T X)^-1

#Note that the fitted values (Y-hat) from a linear model can be obtained with:
fit = lm(y ~ x)
fit$fitted.values

#What is the sum of the squared residuals (where residuals are given by r_i = Y_i - Y-hat_i)?
index = sample(n,N)
sampledat = father.son[index,]
x = sampledat$fheight
y = sampledat$sheight
fit = lm(y~x)
y_hat <- fit$fitted.values
ssr <- sum((y-y_hat)^2) #sum(r_i^2)
ssr

#Our estimate of sigma^2 will be the sum of squared residuals divided by (N - p), the sample size minus the number of terms in the model. Since we have a sample of 50 and 2 terms in the model (an intercept and a slope), our estimate of sigma^2 will be the sum of squared residuals divided by 48. Save this to a variable 'sigma2':
sigma2 = SSR / 48

#QUESTION 2.2.2  
#Form the design matrix X (note: use a capital X!). This can be done by combining a column of 1's with a column of 'x' the father's heights.

X = cbind(rep(1,N), x)

#Now calculate (X^T X)^-1, the inverse of X transpose times X. Use the solve() function for the inverse and t() for the transpose. What is the element in the first row, first column?
X <- cbind(rep(1,N),x)
Y <- solve(crossprod(X)) #equivalent to solve(t(X)%*%X)
Y[1,1]

#QUESTION 2.2.3  
#Now we are one step away from the standard error of beta-hat. Take the diagonals from the (X^T X)^-1 matrix above, using the diag() function. Now multiply our estimate of sigma^2 and the diagonals of this matrix. This is the estimated variance of beta-hat, so take the square root of this. You should end up with two numbers, the standard error for the intercept and the standard error for the slope.

#What is the standard error for the slope?
sigma2<-ssr/48
var(betahat) = sigma^2 *diag(Y) #why diag(Y)?
sqrt(var(betahat))[2]

#In the t-test, the denominator of the t-value is the standard error of the difference. The t-test formula for the standard error of the difference, if we assume equal variance in the two groups is:
SE = sqrt(var(diff))
var(diff) = (1/nx + 1/ny) ( sum { (x_i - mu_x)^2 } + sum { (y_i - mu_y)^2 } ) / (nx + ny - 2) 
===>( (X^T X)^-1 )[2,2] = (1/nx + 1/ny)

#QUESTION 2.4.1  
You can make a design matrix X for a two group comparison either using model.matrix or simply with:

X = cbind(rep(1,nx + ny),rep(c(0,1),c(nx, ny)))

#For a comparison of two groups, where the first group has nx=5 samples, and the second group has ny=7 samples, what is the element in the 1st row and 1st column of X^T X?
nx=5
ny=7
X = cbind(rep(1,nx + ny),rep(c(0,1),c(nx, ny)))
#equivalent to
x <- factor(rep(1,nx+ny))
y <- factor(rep(c(0,1),c(nx,ny)))
model.matrix(x~y)  #build the matrix

crossprod(X)
solve(crossprod(X))
x <- factor(a,c,b,d)
k <- model.matrix(~x)

#complex design
species <- factor(c("A","A","B","B"))
condition <- factor(c("control","treated","control","treated"))
model.matrix(~ species + condition)
#QUESTION 2.5.1  
#Suppose we want to build a contrast of coefficients for the above experimental design.
#What should the contrast vector be, for the contrast of (species=B and condition=control) vs (species=A and condition=treatment)? Assume that the beta vector from the model fit by R is: Intercept, speciesB, conditiontreated.
(1 1 0)-(1 0 1)

QUESTION 2.5.2  (1/1 point)
Use the Rmd script of the spider dataset. Suppose we build a model using two variables: ~ type + leg.
What is the t-value for the contrast of leg pair L4 vs leg pair L2?
fitTL <- lm(friction ~ type + leg, data=spider)
L4vsL2 <- contrast(fitTL,list(leg="L4",type="pull"),list(leg="L2",type="pull"))
L4vsL2

#QUESTION 2.5.3  
#Using Sigma, what is Cov(beta-hat_L4, beta-hat_L2)?

X <- model.matrix(~ type + leg, data=spider)
(Sigma <- sum(fitTL$residuals^2)/(nrow(X) - ncol(X)) * solve(t(X) %*% X))
Our contrast matrix is:

C <- matrix(c(0,0,-1,0,1),1,5)
